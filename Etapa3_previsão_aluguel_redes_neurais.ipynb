{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regressão linear e rede newral com TensorFlow (lembrando que também da pra fazer com o keras)\n",
    "# Vamos o valor do aluguem em Alagoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREPARAÇÃO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos fazer o numpy printouts mais fácil de ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos baixar a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UF</th>\n",
       "      <th>Codigo_do_Municipio</th>\n",
       "      <th>Area_de_Ponderacao</th>\n",
       "      <th>Controle</th>\n",
       "      <th>Peso_Amostral</th>\n",
       "      <th>Regiao</th>\n",
       "      <th>Codigo_da_Mesorregiao</th>\n",
       "      <th>Codigo_da_Microrregiao</th>\n",
       "      <th>Codigo_da_Regiao_Metropolitana</th>\n",
       "      <th>...</th>\n",
       "      <th>Marca_de_imputacao_na_v0218</th>\n",
       "      <th>Marca_de_imputacao_na_v0219</th>\n",
       "      <th>Marca_de_imputacao_na_v0220</th>\n",
       "      <th>Marca_de_imputacao_na_v0221</th>\n",
       "      <th>Marca_de_imputacao_na_v02022</th>\n",
       "      <th>Marca_de_imputacao_na_v0301</th>\n",
       "      <th>Marca_de_imputacao_na_v0401</th>\n",
       "      <th>Marca_de_imputacao_na_v0402</th>\n",
       "      <th>Marca_de_imputacao_na_v0701</th>\n",
       "      <th>Situacao_do_setor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78339</th>\n",
       "      <td>78340</td>\n",
       "      <td>16</td>\n",
       "      <td>808</td>\n",
       "      <td>1600808001001</td>\n",
       "      <td>6186781</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78340</th>\n",
       "      <td>78341</td>\n",
       "      <td>16</td>\n",
       "      <td>808</td>\n",
       "      <td>1600808001001</td>\n",
       "      <td>6186781</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78341</th>\n",
       "      <td>78342</td>\n",
       "      <td>16</td>\n",
       "      <td>808</td>\n",
       "      <td>1600808001001</td>\n",
       "      <td>6186781</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78342</th>\n",
       "      <td>78343</td>\n",
       "      <td>16</td>\n",
       "      <td>808</td>\n",
       "      <td>1600808001001</td>\n",
       "      <td>6186781</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78343</th>\n",
       "      <td>78344</td>\n",
       "      <td>16</td>\n",
       "      <td>808</td>\n",
       "      <td>1600808001001</td>\n",
       "      <td>6186781</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  UF  Codigo_do_Municipio  Area_de_Ponderacao  Controle  \\\n",
       "78339       78340  16                  808       1600808001001   6186781   \n",
       "78340       78341  16                  808       1600808001001   6186781   \n",
       "78341       78342  16                  808       1600808001001   6186781   \n",
       "78342       78343  16                  808       1600808001001   6186781   \n",
       "78343       78344  16                  808       1600808001001   6186781   \n",
       "\n",
       "       Peso_Amostral  Regiao  Codigo_da_Mesorregiao  Codigo_da_Microrregiao  \\\n",
       "78339              4       4                     31                     106   \n",
       "78340              4       4                     31                     106   \n",
       "78341              4       4                     31                     106   \n",
       "78342              4       4                     31                     106   \n",
       "78343              4       4                     31                     106   \n",
       "\n",
       "       Codigo_da_Regiao_Metropolitana        ...          \\\n",
       "78339                              75        ...           \n",
       "78340                              75        ...           \n",
       "78341                              75        ...           \n",
       "78342                              75        ...           \n",
       "78343                              75        ...           \n",
       "\n",
       "       Marca_de_imputacao_na_v0218  Marca_de_imputacao_na_v0219  \\\n",
       "78339                          NaN                          NaN   \n",
       "78340                          NaN                          NaN   \n",
       "78341                          NaN                          NaN   \n",
       "78342                          NaN                          NaN   \n",
       "78343                          0.0                          1.0   \n",
       "\n",
       "       Marca_de_imputacao_na_v0220  Marca_de_imputacao_na_v0221  \\\n",
       "78339                          NaN                          NaN   \n",
       "78340                          NaN                          NaN   \n",
       "78341                          NaN                          NaN   \n",
       "78342                          NaN                          NaN   \n",
       "78343                          5.0                          9.0   \n",
       "\n",
       "       Marca_de_imputacao_na_v02022  Marca_de_imputacao_na_v0301  \\\n",
       "78339                           NaN                          NaN   \n",
       "78340                           NaN                          NaN   \n",
       "78341                           NaN                          NaN   \n",
       "78342                           NaN                          NaN   \n",
       "78343                           9.0                          9.0   \n",
       "\n",
       "       Marca_de_imputacao_na_v0401  Marca_de_imputacao_na_v0402  \\\n",
       "78339                          NaN                          NaN   \n",
       "78340                          NaN                          NaN   \n",
       "78341                          NaN                          NaN   \n",
       "78342                          NaN                          NaN   \n",
       "78343                          9.0                          9.0   \n",
       "\n",
       "       Marca_de_imputacao_na_v0701  Situacao_do_setor  \n",
       "78339                          NaN                NaN  \n",
       "78340                          NaN                NaN  \n",
       "78341                          NaN                NaN  \n",
       "78342                          NaN                NaN  \n",
       "78343                          NaN                NaN  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset=pd.DataFrame(pd.read_csv('C:/Users/Cássio/Desktop/AP/AP/censo2010.csv',engine='python'))\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# como a base de dados é muito grande para trabalhar em um computador pessoal, vamos pegar só 50% da mesma\n",
    "# se for para utilizar processamento distribuido dá pra fazer tranquilamente com a base toda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "dataset=dataset.head(int(len(dataset)*(n/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UF</th>\n",
       "      <th>Codigo_do_Municipio</th>\n",
       "      <th>Area_de_Ponderacao</th>\n",
       "      <th>Controle</th>\n",
       "      <th>Peso_Amostral</th>\n",
       "      <th>Regiao</th>\n",
       "      <th>Codigo_da_Mesorregiao</th>\n",
       "      <th>Codigo_da_Microrregiao</th>\n",
       "      <th>Codigo_da_Regiao_Metropolitana</th>\n",
       "      <th>...</th>\n",
       "      <th>Marca_de_imputacao_na_v0218</th>\n",
       "      <th>Marca_de_imputacao_na_v0219</th>\n",
       "      <th>Marca_de_imputacao_na_v0220</th>\n",
       "      <th>Marca_de_imputacao_na_v0221</th>\n",
       "      <th>Marca_de_imputacao_na_v02022</th>\n",
       "      <th>Marca_de_imputacao_na_v0301</th>\n",
       "      <th>Marca_de_imputacao_na_v0401</th>\n",
       "      <th>Marca_de_imputacao_na_v0402</th>\n",
       "      <th>Marca_de_imputacao_na_v0701</th>\n",
       "      <th>Situacao_do_setor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39167</th>\n",
       "      <td>39168</td>\n",
       "      <td>16</td>\n",
       "      <td>303</td>\n",
       "      <td>1600303005013</td>\n",
       "      <td>2073782</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39168</th>\n",
       "      <td>39169</td>\n",
       "      <td>16</td>\n",
       "      <td>303</td>\n",
       "      <td>1600303005013</td>\n",
       "      <td>2073782</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39169</th>\n",
       "      <td>39170</td>\n",
       "      <td>16</td>\n",
       "      <td>303</td>\n",
       "      <td>1600303005013</td>\n",
       "      <td>2073782</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39170</th>\n",
       "      <td>39171</td>\n",
       "      <td>16</td>\n",
       "      <td>303</td>\n",
       "      <td>1600303005013</td>\n",
       "      <td>2073782</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39171</th>\n",
       "      <td>39172</td>\n",
       "      <td>16</td>\n",
       "      <td>303</td>\n",
       "      <td>1600303005013</td>\n",
       "      <td>2073782</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  UF  Codigo_do_Municipio  Area_de_Ponderacao  Controle  \\\n",
       "39167       39168  16                  303       1600303005013   2073782   \n",
       "39168       39169  16                  303       1600303005013   2073782   \n",
       "39169       39170  16                  303       1600303005013   2073782   \n",
       "39170       39171  16                  303       1600303005013   2073782   \n",
       "39171       39172  16                  303       1600303005013   2073782   \n",
       "\n",
       "       Peso_Amostral  Regiao  Codigo_da_Mesorregiao  Codigo_da_Microrregiao  \\\n",
       "39167              7       0                     44                     618   \n",
       "39168              7       0                     44                     618   \n",
       "39169              7       0                     44                     618   \n",
       "39170              7       0                     44                     618   \n",
       "39171              7       0                     44                     618   \n",
       "\n",
       "       Codigo_da_Regiao_Metropolitana        ...          \\\n",
       "39167                               4        ...           \n",
       "39168                               4        ...           \n",
       "39169                               4        ...           \n",
       "39170                               4        ...           \n",
       "39171                               4        ...           \n",
       "\n",
       "       Marca_de_imputacao_na_v0218  Marca_de_imputacao_na_v0219  \\\n",
       "39167                          NaN                          NaN   \n",
       "39168                          NaN                          NaN   \n",
       "39169                          NaN                          NaN   \n",
       "39170                          NaN                          NaN   \n",
       "39171                          NaN                          NaN   \n",
       "\n",
       "       Marca_de_imputacao_na_v0220  Marca_de_imputacao_na_v0221  \\\n",
       "39167                          NaN                          NaN   \n",
       "39168                          NaN                          NaN   \n",
       "39169                          NaN                          NaN   \n",
       "39170                          NaN                          NaN   \n",
       "39171                          NaN                          NaN   \n",
       "\n",
       "       Marca_de_imputacao_na_v02022  Marca_de_imputacao_na_v0301  \\\n",
       "39167                           NaN                          NaN   \n",
       "39168                           NaN                          NaN   \n",
       "39169                           NaN                          NaN   \n",
       "39170                           NaN                          NaN   \n",
       "39171                           NaN                          NaN   \n",
       "\n",
       "       Marca_de_imputacao_na_v0401  Marca_de_imputacao_na_v0402  \\\n",
       "39167                          NaN                          NaN   \n",
       "39168                          NaN                          NaN   \n",
       "39169                          NaN                          NaN   \n",
       "39170                          NaN                          NaN   \n",
       "39171                          NaN                          NaN   \n",
       "\n",
       "       Marca_de_imputacao_na_v0701  Situacao_do_setor  \n",
       "39167                          NaN                NaN  \n",
       "39168                          NaN                NaN  \n",
       "39169                          NaN                NaN  \n",
       "39170                          NaN                NaN  \n",
       "39171                          NaN                NaN  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos ver um sumário dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UF</th>\n",
       "      <th>Codigo_do_Municipio</th>\n",
       "      <th>Area_de_Ponderacao</th>\n",
       "      <th>Controle</th>\n",
       "      <th>Peso_Amostral</th>\n",
       "      <th>Regiao</th>\n",
       "      <th>Codigo_da_Mesorregiao</th>\n",
       "      <th>Codigo_da_Microrregiao</th>\n",
       "      <th>Codigo_da_Regiao_Metropolitana</th>\n",
       "      <th>...</th>\n",
       "      <th>Marca_de_imputacao_na_v0218</th>\n",
       "      <th>Marca_de_imputacao_na_v0219</th>\n",
       "      <th>Marca_de_imputacao_na_v0220</th>\n",
       "      <th>Marca_de_imputacao_na_v0221</th>\n",
       "      <th>Marca_de_imputacao_na_v02022</th>\n",
       "      <th>Marca_de_imputacao_na_v0301</th>\n",
       "      <th>Marca_de_imputacao_na_v0401</th>\n",
       "      <th>Marca_de_imputacao_na_v0402</th>\n",
       "      <th>Marca_de_imputacao_na_v0701</th>\n",
       "      <th>Situacao_do_setor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39172.000000</td>\n",
       "      <td>39172.0</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>3.917200e+04</td>\n",
       "      <td>3.917200e+04</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4907.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>4905.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19586.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>259.486623</td>\n",
       "      <td>1.600259e+12</td>\n",
       "      <td>3.059794e+06</td>\n",
       "      <td>8.019989</td>\n",
       "      <td>4.418309</td>\n",
       "      <td>50.676453</td>\n",
       "      <td>500.728837</td>\n",
       "      <td>48.981288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359079</td>\n",
       "      <td>1.493986</td>\n",
       "      <td>5.326198</td>\n",
       "      <td>0.535576</td>\n",
       "      <td>1.509072</td>\n",
       "      <td>4.364730</td>\n",
       "      <td>1.227319</td>\n",
       "      <td>4.408359</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11308.126709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.644341</td>\n",
       "      <td>7.064586e+07</td>\n",
       "      <td>1.792047e+06</td>\n",
       "      <td>3.910278</td>\n",
       "      <td>2.883967</td>\n",
       "      <td>29.128580</td>\n",
       "      <td>290.341162</td>\n",
       "      <td>28.936820</td>\n",
       "      <td>...</td>\n",
       "      <td>1.657686</td>\n",
       "      <td>1.541836</td>\n",
       "      <td>1.420119</td>\n",
       "      <td>1.928686</td>\n",
       "      <td>2.592885</td>\n",
       "      <td>2.387625</td>\n",
       "      <td>2.550691</td>\n",
       "      <td>2.851728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.600055e+12</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9793.750000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>1.600238e+12</td>\n",
       "      <td>1.474547e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19586.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1.600303e+12</td>\n",
       "      <td>3.025731e+06</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29379.250000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1.600303e+12</td>\n",
       "      <td>4.630582e+06</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39172.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1.600303e+12</td>\n",
       "      <td>6.190263e+06</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       UF  Codigo_do_Municipio  Area_de_Ponderacao  \\\n",
       "count  39172.000000  39172.0         39172.000000        3.917200e+04   \n",
       "mean   19586.500000     16.0           259.486623        1.600259e+12   \n",
       "std    11308.126709      0.0            70.644341        7.064586e+07   \n",
       "min        1.000000     16.0            55.000000        1.600055e+12   \n",
       "25%     9793.750000     16.0           238.000000        1.600238e+12   \n",
       "50%    19586.500000     16.0           303.000000        1.600303e+12   \n",
       "75%    29379.250000     16.0           303.000000        1.600303e+12   \n",
       "max    39172.000000     16.0           303.000000        1.600303e+12   \n",
       "\n",
       "           Controle  Peso_Amostral        Regiao  Codigo_da_Mesorregiao  \\\n",
       "count  3.917200e+04   39172.000000  39172.000000           39172.000000   \n",
       "mean   3.059794e+06       8.019989      4.418309              50.676453   \n",
       "std    1.792047e+06       3.910278      2.883967              29.128580   \n",
       "min    9.000000e+00       1.000000      0.000000               0.000000   \n",
       "25%    1.474547e+06       4.000000      2.000000              26.000000   \n",
       "50%    3.025731e+06       9.000000      4.000000              51.000000   \n",
       "75%    4.630582e+06      11.000000      7.000000              76.000000   \n",
       "max    6.190263e+06      24.000000      9.000000              99.000000   \n",
       "\n",
       "       Codigo_da_Microrregiao  Codigo_da_Regiao_Metropolitana  \\\n",
       "count            39172.000000                    39172.000000   \n",
       "mean               500.728837                       48.981288   \n",
       "std                290.341162                       28.936820   \n",
       "min                  0.000000                        0.000000   \n",
       "25%                253.000000                       24.000000   \n",
       "50%                498.000000                       49.000000   \n",
       "75%                755.000000                       74.000000   \n",
       "max                999.000000                       99.000000   \n",
       "\n",
       "             ...          Marca_de_imputacao_na_v0218  \\\n",
       "count        ...                          4907.000000   \n",
       "mean         ...                             0.359079   \n",
       "std          ...                             1.657686   \n",
       "min          ...                             0.000000   \n",
       "25%          ...                             0.000000   \n",
       "50%          ...                             0.000000   \n",
       "75%          ...                             0.000000   \n",
       "max          ...                             9.000000   \n",
       "\n",
       "       Marca_de_imputacao_na_v0219  Marca_de_imputacao_na_v0220  \\\n",
       "count                  4905.000000                  4905.000000   \n",
       "mean                      1.493986                     5.326198   \n",
       "std                       1.541836                     1.420119   \n",
       "min                       1.000000                     0.000000   \n",
       "25%                       1.000000                     5.000000   \n",
       "50%                       1.000000                     6.000000   \n",
       "75%                       1.000000                     6.000000   \n",
       "max                       9.000000                     9.000000   \n",
       "\n",
       "       Marca_de_imputacao_na_v0221  Marca_de_imputacao_na_v02022  \\\n",
       "count                  4905.000000                   4905.000000   \n",
       "mean                      0.535576                      1.509072   \n",
       "std                       1.928686                      2.592885   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                       0.000000                      0.000000   \n",
       "75%                       0.000000                      1.000000   \n",
       "max                       9.000000                      9.000000   \n",
       "\n",
       "       Marca_de_imputacao_na_v0301  Marca_de_imputacao_na_v0401  \\\n",
       "count                  4905.000000                  4905.000000   \n",
       "mean                      4.364730                     1.227319   \n",
       "std                       2.387625                     2.550691   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       3.000000                     0.000000   \n",
       "50%                       4.000000                     0.000000   \n",
       "75%                       6.000000                     0.000000   \n",
       "max                       9.000000                     9.000000   \n",
       "\n",
       "       Marca_de_imputacao_na_v0402  Marca_de_imputacao_na_v0701  \\\n",
       "count                  4905.000000                         22.0   \n",
       "mean                      4.408359                          8.0   \n",
       "std                       2.851728                          0.0   \n",
       "min                       0.000000                          8.0   \n",
       "25%                       3.000000                          8.0   \n",
       "50%                       3.000000                          8.0   \n",
       "75%                       8.000000                          8.0   \n",
       "max                       9.000000                          8.0   \n",
       "\n",
       "       Situacao_do_setor  \n",
       "count               22.0  \n",
       "mean                 0.0  \n",
       "std                  0.0  \n",
       "min                  0.0  \n",
       "25%                  0.0  \n",
       "50%                  0.0  \n",
       "75%                  0.0  \n",
       "max                  0.0  \n",
       "\n",
       "[8 rows x 77 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A nossa base de dados contem valores faltantes, vamo ver quantos valores faltantes há em cada linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                  0\n",
       "UF                                                          0\n",
       "Codigo_do_Municipio                                         0\n",
       "Area_de_Ponderacao                                          0\n",
       "Controle                                                    0\n",
       "Peso_Amostral                                               0\n",
       "Regiao                                                      0\n",
       "Codigo_da_Mesorregiao                                       0\n",
       "Codigo_da_Microrregiao                                      0\n",
       "Codigo_da_Regiao_Metropolitana                              0\n",
       "Situacao_do_Domicilio                                       0\n",
       "Especie_de_Unidade_Visitada                                 0\n",
       "Tipo_de_Especie                                             0\n",
       "Domicilio_condicao_de_ocupacao                              0\n",
       "Valor_do_aluguel_(em_reais)                                 0\n",
       "Aluguel_em_nº_de_salarios_minimos                           0\n",
       "Material_predominante_nas_paredes_externas                  0\n",
       "Nº_de_comodos                                               0\n",
       "Densidade_de_morador/comodo                                 0\n",
       "Comodos_como_dormitorio_numero                              0\n",
       "Densidade_de_morador/dormitorio                             0\n",
       "Banheiros_de_uso_exclusivo_numero                       38329\n",
       "Sanitario_ou_buraco_para_dejecao/existencia             38329\n",
       "Esgotamento_sanitario/tipo                                  0\n",
       "Abastecimento_de_agua/forma                                 0\n",
       "Abastecimento_de_agua_canalizacao                           0\n",
       "lixo/destino                                                0\n",
       "energia_eletrica_existencia                                 0\n",
       "ecistencia_de_medidor_ou_relogio_de_energia_eletrica        0\n",
       "radio_existencia                                            0\n",
       "                                                        ...  \n",
       "Especie_da_Unidade_Domestica                            31499\n",
       "Adequacao_da_moradia                                    31499\n",
       "Marca_de_imputacao_na_v0201                             31499\n",
       "Marca_de_imputacao_na_v2011                             31499\n",
       "Marca_de_imputacao_na_v0202                             31499\n",
       "Marca_de_imputacao_na_v0203                             31499\n",
       "Marca_de_imputacao_na_v0204                             39126\n",
       "Marca_de_imputacao_na_v0205                             39126\n",
       "Marca_de_imputacao_na_v0206                             39126\n",
       "Marca_de_imputacao_na_v0207                             39126\n",
       "Marca_de_imputacao_na_v0208                             39126\n",
       "Marca_de_imputacao_na_v0209                             39126\n",
       "Marca_de_imputacao_na_v0210                             39126\n",
       "Marca_de_imputacao_na_v0211                             34243\n",
       "Marca_de_imputacao_na_v0212                             34265\n",
       "Marca_de_imputacao_na_v0213                             34265\n",
       "Marca_de_imputacao_na_v0214                             34265\n",
       "Marca_de_imputacao_na_v0215                             34265\n",
       "Marca_de_imputacao_na_v0216                             34265\n",
       "Marca_de_imputacao_na_v0217                             34265\n",
       "Marca_de_imputacao_na_v0218                             34265\n",
       "Marca_de_imputacao_na_v0219                             34267\n",
       "Marca_de_imputacao_na_v0220                             34267\n",
       "Marca_de_imputacao_na_v0221                             34267\n",
       "Marca_de_imputacao_na_v02022                            34267\n",
       "Marca_de_imputacao_na_v0301                             34267\n",
       "Marca_de_imputacao_na_v0401                             34267\n",
       "Marca_de_imputacao_na_v0402                             34267\n",
       "Marca_de_imputacao_na_v0701                             39150\n",
       "Situacao_do_setor                                       39150\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Como eu já verifiquei as variáveis que quero, vou selecionar na base apenas estas variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=dataset[['Regiao','Valor_do_aluguel_(em_reais)','Nº_de_comodos','Comodos_como_dormitorio_numero']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset, columns=['Regiao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=dataset.rename(columns={'Valor_do_aluguel_(em_reais)':'Valor_do_aluguel_em_reais'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=dataset.rename(columns={'Nº_de_comodos':'N_de_comodos'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para facilitar vamos deletar as linhas com valores nulos para deixar este tutorial inicial simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor_do_aluguel_em_reais</th>\n",
       "      <th>N_de_comodos</th>\n",
       "      <th>Comodos_como_dormitorio_numero</th>\n",
       "      <th>Regiao_0</th>\n",
       "      <th>Regiao_1</th>\n",
       "      <th>Regiao_2</th>\n",
       "      <th>Regiao_3</th>\n",
       "      <th>Regiao_4</th>\n",
       "      <th>Regiao_5</th>\n",
       "      <th>Regiao_6</th>\n",
       "      <th>Regiao_7</th>\n",
       "      <th>Regiao_8</th>\n",
       "      <th>Regiao_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20030</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20030</td>\n",
       "      <td>22</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20030</td>\n",
       "      <td>61</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20030</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20030</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20030</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20030</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20030</td>\n",
       "      <td>52</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20030</td>\n",
       "      <td>61</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20030</td>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20030</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20030</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20030</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20030</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20030</td>\n",
       "      <td>72</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20030</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20030</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20030</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20030</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20030</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39142</th>\n",
       "      <td>20030</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39143</th>\n",
       "      <td>20030</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39144</th>\n",
       "      <td>20030</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39145</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39146</th>\n",
       "      <td>20030</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39147</th>\n",
       "      <td>20030</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39148</th>\n",
       "      <td>20030</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39149</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39150</th>\n",
       "      <td>20030</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39151</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39152</th>\n",
       "      <td>20030</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>20030</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39154</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39156</th>\n",
       "      <td>20030</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39157</th>\n",
       "      <td>20030</td>\n",
       "      <td>21</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39158</th>\n",
       "      <td>20030</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39159</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39160</th>\n",
       "      <td>20030</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39161</th>\n",
       "      <td>20030</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39162</th>\n",
       "      <td>20030</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39163</th>\n",
       "      <td>20030</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39164</th>\n",
       "      <td>20030</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39165</th>\n",
       "      <td>20030</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39166</th>\n",
       "      <td>20030</td>\n",
       "      <td>61</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39167</th>\n",
       "      <td>20030</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39168</th>\n",
       "      <td>20030</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39169</th>\n",
       "      <td>20030</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39170</th>\n",
       "      <td>20030</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39171</th>\n",
       "      <td>20030</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39172 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Valor_do_aluguel_em_reais  N_de_comodos  \\\n",
       "0                          20030            12   \n",
       "1                          20030            42   \n",
       "2                          20030            32   \n",
       "3                          20030            21   \n",
       "4                          20030            51   \n",
       "5                          20030            11   \n",
       "6                          20030            22   \n",
       "7                          20030            61   \n",
       "8                          20030            72   \n",
       "9                          20030            31   \n",
       "10                         20030            41   \n",
       "11                         20030            81   \n",
       "12                         20030            11   \n",
       "13                         20030            52   \n",
       "14                         20030            61   \n",
       "15                         20030            41   \n",
       "16                         20030            21   \n",
       "17                         20030            31   \n",
       "18                         20030            12   \n",
       "19                         20030            21   \n",
       "20                         20030            31   \n",
       "21                         20030            42   \n",
       "22                         20030            12   \n",
       "23                         20030            62   \n",
       "24                         20030            72   \n",
       "25                         20030            52   \n",
       "26                         20030            11   \n",
       "27                         20030            22   \n",
       "28                         20030            32   \n",
       "29                         20030            41   \n",
       "...                          ...           ...   \n",
       "39142                      20030            41   \n",
       "39143                      20030            32   \n",
       "39144                      20030            72   \n",
       "39145                      20030            12   \n",
       "39146                      20030            61   \n",
       "39147                      20030            52   \n",
       "39148                      20030            42   \n",
       "39149                      20030            31   \n",
       "39150                      20030            22   \n",
       "39151                      20030            12   \n",
       "39152                      20030            32   \n",
       "39153                      20030            22   \n",
       "39154                      20030            12   \n",
       "39155                      20030            31   \n",
       "39156                      20030            41   \n",
       "39157                      20030            21   \n",
       "39158                      20030            21   \n",
       "39159                      20030            31   \n",
       "39160                      20030            12   \n",
       "39161                      20030            11   \n",
       "39162                      20030            22   \n",
       "39163                      20030            31   \n",
       "39164                      20030            91   \n",
       "39165                      20030            52   \n",
       "39166                      20030            61   \n",
       "39167                      20030            72   \n",
       "39168                      20030            82   \n",
       "39169                      20030            42   \n",
       "39170                      20030            32   \n",
       "39171                      20030             2   \n",
       "\n",
       "       Comodos_como_dormitorio_numero  Regiao_0  Regiao_1  Regiao_2  Regiao_3  \\\n",
       "0                                   0         0         0         0         0   \n",
       "1                                  20         0         0         0         0   \n",
       "2                                  50         0         0         0         0   \n",
       "3                                  30         0         0         0         0   \n",
       "4                                  90         0         0         0         0   \n",
       "5                                  70         0         0         0         0   \n",
       "6                                  80         0         0         0         0   \n",
       "7                                  40         0         0         0         0   \n",
       "8                                  20         0         0         0         0   \n",
       "9                                  20         0         0         0         0   \n",
       "10                                  0         0         0         0         0   \n",
       "11                                 50         0         0         0         0   \n",
       "12                                  0         1         0         0         0   \n",
       "13                                 90         0         0         0         0   \n",
       "14                                 90         0         0         0         0   \n",
       "15                                 60         0         0         0         0   \n",
       "16                                 10         0         0         0         0   \n",
       "17                                 60         0         0         0         0   \n",
       "18                                 70         0         0         0         0   \n",
       "19                                 10         0         0         0         0   \n",
       "20                                 40         0         0         0         0   \n",
       "21                                 30         0         0         0         0   \n",
       "22                                 10         0         0         0         0   \n",
       "23                                 70         0         0         0         0   \n",
       "24                                 40         0         0         0         0   \n",
       "25                                  0         0         0         0         0   \n",
       "26                                 60         0         0         0         0   \n",
       "27                                 70         0         0         0         0   \n",
       "28                                 10         0         0         0         0   \n",
       "29                                  0         0         0         0         0   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "39142                              30         0         1         0         0   \n",
       "39143                              50         0         1         0         0   \n",
       "39144                              50         0         0         0         0   \n",
       "39145                              80         0         0         0         0   \n",
       "39146                              70         0         0         0         0   \n",
       "39147                              10         0         0         0         0   \n",
       "39148                              60         0         0         0         0   \n",
       "39149                              10         0         0         0         0   \n",
       "39150                              40         0         0         0         0   \n",
       "39151                              20         0         0         0         0   \n",
       "39152                              40         0         0         0         0   \n",
       "39153                              70         0         0         0         0   \n",
       "39154                              20         0         0         0         0   \n",
       "39155                              10         0         0         0         0   \n",
       "39156                              10         0         0         0         0   \n",
       "39157                              70         0         0         0         0   \n",
       "39158                              30         0         0         0         0   \n",
       "39159                              30         0         0         0         0   \n",
       "39160                              20         0         0         0         0   \n",
       "39161                              40         0         0         0         0   \n",
       "39162                               0         0         0         0         0   \n",
       "39163                              10         0         0         0         0   \n",
       "39164                              80         1         0         0         0   \n",
       "39165                              60         1         0         0         0   \n",
       "39166                              90         1         0         0         0   \n",
       "39167                              80         1         0         0         0   \n",
       "39168                              60         1         0         0         0   \n",
       "39169                              90         1         0         0         0   \n",
       "39170                              20         1         0         0         0   \n",
       "39171                              80         1         0         0         0   \n",
       "\n",
       "       Regiao_4  Regiao_5  Regiao_6  Regiao_7  Regiao_8  Regiao_9  \n",
       "0             0         0         0         0         1         0  \n",
       "1             0         0         0         0         1         0  \n",
       "2             0         0         0         0         1         0  \n",
       "3             0         0         0         0         1         0  \n",
       "4             0         0         0         1         0         0  \n",
       "5             0         0         0         1         0         0  \n",
       "6             0         0         0         1         0         0  \n",
       "7             0         0         0         1         0         0  \n",
       "8             0         0         0         1         0         0  \n",
       "9             0         0         0         1         0         0  \n",
       "10            0         0         0         1         0         0  \n",
       "11            0         0         0         1         0         0  \n",
       "12            0         0         0         0         0         0  \n",
       "13            0         0         0         0         0         1  \n",
       "14            0         0         0         0         0         1  \n",
       "15            0         0         0         0         0         1  \n",
       "16            0         0         0         0         0         1  \n",
       "17            0         0         0         0         0         1  \n",
       "18            0         0         0         0         0         1  \n",
       "19            0         1         0         0         0         0  \n",
       "20            0         1         0         0         0         0  \n",
       "21            0         1         0         0         0         0  \n",
       "22            0         1         0         0         0         0  \n",
       "23            0         1         0         0         0         0  \n",
       "24            0         1         0         0         0         0  \n",
       "25            0         1         0         0         0         0  \n",
       "26            0         0         0         0         1         0  \n",
       "27            0         0         0         0         1         0  \n",
       "28            0         0         0         1         0         0  \n",
       "29            0         0         0         1         0         0  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "39142         0         0         0         0         0         0  \n",
       "39143         0         0         0         0         0         0  \n",
       "39144         0         1         0         0         0         0  \n",
       "39145         0         1         0         0         0         0  \n",
       "39146         0         1         0         0         0         0  \n",
       "39147         0         1         0         0         0         0  \n",
       "39148         0         1         0         0         0         0  \n",
       "39149         0         1         0         0         0         0  \n",
       "39150         0         1         0         0         0         0  \n",
       "39151         0         0         0         0         0         1  \n",
       "39152         0         0         0         0         0         1  \n",
       "39153         0         0         0         0         0         1  \n",
       "39154         0         0         0         0         0         1  \n",
       "39155         0         0         0         0         0         1  \n",
       "39156         0         0         0         0         0         1  \n",
       "39157         0         0         0         0         0         1  \n",
       "39158         0         0         0         0         1         0  \n",
       "39159         0         0         0         0         1         0  \n",
       "39160         0         0         0         0         1         0  \n",
       "39161         0         0         0         0         1         0  \n",
       "39162         0         0         0         0         1         0  \n",
       "39163         0         0         0         0         1         0  \n",
       "39164         0         0         0         0         0         0  \n",
       "39165         0         0         0         0         0         0  \n",
       "39166         0         0         0         0         0         0  \n",
       "39167         0         0         0         0         0         0  \n",
       "39168         0         0         0         0         0         0  \n",
       "39169         0         0         0         0         0         0  \n",
       "39170         0         0         0         0         0         0  \n",
       "39171         0         0         0         0         0         0  \n",
       "\n",
       "[39172 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos separar a base de dados entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Valor_do_aluguel_em_reais</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>18943.553513</td>\n",
       "      <td>3116.005779</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>20030.0</td>\n",
       "      <td>20030.0</td>\n",
       "      <td>20030.0</td>\n",
       "      <td>20040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_de_comodos</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>32.179112</td>\n",
       "      <td>19.390900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comodos_como_dormitorio_numero</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>43.877114</td>\n",
       "      <td>28.368784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_0</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.106835</td>\n",
       "      <td>0.308908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_1</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.100549</td>\n",
       "      <td>0.300735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_2</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.101634</td>\n",
       "      <td>0.302171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_3</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.105591</td>\n",
       "      <td>0.307318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_4</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.097422</td>\n",
       "      <td>0.296536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_5</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.098666</td>\n",
       "      <td>0.298218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_6</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.092699</td>\n",
       "      <td>0.290015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_7</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.103836</td>\n",
       "      <td>0.305052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_8</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.294489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regiao_9</th>\n",
       "      <td>31338.0</td>\n",
       "      <td>0.096847</td>\n",
       "      <td>0.295754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count          mean          std      min  \\\n",
       "Valor_do_aluguel_em_reais       31338.0  18943.553513  3116.005779  10010.0   \n",
       "N_de_comodos                    31338.0     32.179112    19.390900      1.0   \n",
       "Comodos_como_dormitorio_numero  31338.0     43.877114    28.368784      0.0   \n",
       "Regiao_0                        31338.0      0.106835     0.308908      0.0   \n",
       "Regiao_1                        31338.0      0.100549     0.300735      0.0   \n",
       "Regiao_2                        31338.0      0.101634     0.302171      0.0   \n",
       "Regiao_3                        31338.0      0.105591     0.307318      0.0   \n",
       "Regiao_4                        31338.0      0.097422     0.296536      0.0   \n",
       "Regiao_5                        31338.0      0.098666     0.298218      0.0   \n",
       "Regiao_6                        31338.0      0.092699     0.290015      0.0   \n",
       "Regiao_7                        31338.0      0.103836     0.305052      0.0   \n",
       "Regiao_8                        31338.0      0.095922     0.294489      0.0   \n",
       "Regiao_9                        31338.0      0.096847     0.295754      0.0   \n",
       "\n",
       "                                    25%      50%      75%      max  \n",
       "Valor_do_aluguel_em_reais       20030.0  20030.0  20030.0  20040.0  \n",
       "N_de_comodos                       12.0     31.0     42.0     92.0  \n",
       "Comodos_como_dormitorio_numero     20.0     40.0     70.0     90.0  \n",
       "Regiao_0                            0.0      0.0      0.0      1.0  \n",
       "Regiao_1                            0.0      0.0      0.0      1.0  \n",
       "Regiao_2                            0.0      0.0      0.0      1.0  \n",
       "Regiao_3                            0.0      0.0      0.0      1.0  \n",
       "Regiao_4                            0.0      0.0      0.0      1.0  \n",
       "Regiao_5                            0.0      0.0      0.0      1.0  \n",
       "Regiao_6                            0.0      0.0      0.0      1.0  \n",
       "Regiao_7                            0.0      0.0      0.0      1.0  \n",
       "Regiao_8                            0.0      0.0      0.0      1.0  \n",
       "Regiao_9                            0.0      0.0      0.0      1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos separar a variável que queremos prever das demais\n",
    "# primeiro vamos copiar nossa base de dados em train_y (cópia da base treino) e test_y (cópia da base teste)\n",
    "# e em seguida retiramos a variávl dependentes desta base, deixando nela apenas as variáveis independentes (x) e criando a\n",
    "# novas bases de teste e treino apenas com a dependente (respectivamente test_y e train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OBS: SE EU QUISER APLICAR UMA REGRESSÃO SIMPLES, BASTA COLOCAR APENAS UMA VARIÁVEL NA BASE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_dataset.copy()\n",
    "test_y = test_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x=pd.concat([train_y.pop(x) for x in ['N_de_comodos','Comodos_como_dormitorio_numero','Regiao_0','Regiao_1','Regiao_2','Regiao_3','Regiao_4','Regiao_5','Regiao_6','Regiao_7','Regiao_8','Regiao_9']], axis=1)\n",
    "test_x=pd.concat([test_y.pop(x) for x in ['N_de_comodos','Comodos_como_dormitorio_numero','Regiao_0','Regiao_1','Regiao_2','Regiao_3','Regiao_4','Regiao_5','Regiao_6','Regiao_7','Regiao_8','Regiao_9']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agora temos que normalizar os dados, ficando a maioria das variáveis entre -1\n",
    "# e 1, mas podendo variar para além desse intervalo. Essa etapa é MUITO\n",
    "# IMPORTANTE pois melhora o poder preditivo do modelo e as variáveis estão\n",
    "# compreendidas em um intervalo maior de valores não tendem a apresentar uma\n",
    "# relevância maior, o que ocorre se não tivermos a normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.179 43.877  0.107  0.101  0.102  0.106  0.097  0.099  0.093  0.104\n",
      "  0.096  0.097]\n"
     ]
    }
   ],
   "source": [
    "train_dataset.describe().transpose()[['mean', 'std']]\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_x))\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos ver como ficaram os dados após a normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first = np.array(train_x[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[11  0  0  0  0  1  0  0  0  0  0  0]]\n",
      "\n",
      "Normalized: [[-1.09 -1.55 -0.35 -0.33 -0.34  2.91 -0.33 -0.33 -0.32 -0.34 -0.33 -0.33]]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################REGRESSÃO MULTIPLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparados os dados, vamos aplicar a regressão linear multipla utilizando as variáveis independentes\n",
    "# que estão na nossa base de dados, normalizadas e salvas no objeto \"normalizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos ver se o resultado deste modelo (abaixo apenas as 10 primeiras observações)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.727],\n",
       "       [ 1.28 ],\n",
       "       [ 1.788],\n",
       "       [ 0.061],\n",
       "       [ 0.068],\n",
       "       [ 1.012],\n",
       "       [-0.057],\n",
       "       [-1.45 ],\n",
       "       [ 2.208],\n",
       "       [-0.128]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.predict(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quando chamamos o modelo, sua matriz de pesos será construída (são os parâmetros de cada uma das variáveis independentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense/kernel:0' shape=(12, 1) dtype=float32, numpy=\n",
       "array([[ 0.056],\n",
       "       [-0.233],\n",
       "       [ 0.431],\n",
       "       [ 0.259],\n",
       "       [-0.031],\n",
       "       [ 0.43 ],\n",
       "       [-0.622],\n",
       "       [-0.221],\n",
       "       [-0.559],\n",
       "       [-0.101],\n",
       "       [-0.403],\n",
       "       [ 0.674]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.layers[1].kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# após treinar, temos que compilar o modelo, como estamos prevendo uma variável contínua e não binária,\n",
    "# utilizamos o loss=\"mean_absolute_error\" se estivéssemos prevendo uma variável dummy (binária, 0 ou 1),\n",
    "# o loss seria \"binary_crossentropy\" o optimizer poderia continuar sendo \"adam\" mas teríamos que\n",
    "# acrescentaro termo metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# epochs=100 indica que o modelo será treinado passando 100 vezes pela base de treino\n",
    "# o argumento verbose=1 indica que queremos ver na tela as iterações do modelo\n",
    "# com verbose=0 o modelo é treinado e só mostra o tempo que gastou, pois especificamos %%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 18911.8438 - val_loss: 18836.0391\n",
      "Epoch 2/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18833.3828 - val_loss: 18757.8594\n",
      "Epoch 3/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18754.9082 - val_loss: 18679.6367\n",
      "Epoch 4/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18676.4883 - val_loss: 18601.4375\n",
      "Epoch 5/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18598.0215 - val_loss: 18523.2441\n",
      "Epoch 6/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18519.5762 - val_loss: 18445.0332\n",
      "Epoch 7/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 18441.1035 - val_loss: 18366.8203\n",
      "Epoch 8/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18362.6719 - val_loss: 18288.6582\n",
      "Epoch 9/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18284.2598 - val_loss: 18210.4883\n",
      "Epoch 10/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18205.8398 - val_loss: 18132.3203\n",
      "Epoch 11/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18127.3887 - val_loss: 18054.1367\n",
      "Epoch 12/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18048.9590 - val_loss: 17975.9473\n",
      "Epoch 13/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 17970.5293 - val_loss: 17897.7637\n",
      "Epoch 14/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17892.0957 - val_loss: 17819.5879\n",
      "Epoch 15/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17813.6484 - val_loss: 17741.4043\n",
      "Epoch 16/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17735.2383 - val_loss: 17663.2305\n",
      "Epoch 17/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17656.8027 - val_loss: 17585.0254\n",
      "Epoch 18/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17578.3711 - val_loss: 17506.8672\n",
      "Epoch 19/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17499.9395 - val_loss: 17428.6836\n",
      "Epoch 20/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17421.5078 - val_loss: 17350.5059\n",
      "Epoch 21/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17343.0801 - val_loss: 17272.3184\n",
      "Epoch 22/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17264.6582 - val_loss: 17194.1387\n",
      "Epoch 23/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17186.2227 - val_loss: 17115.9551\n",
      "Epoch 24/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 17107.7734 - val_loss: 17037.7793\n",
      "Epoch 25/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17029.3359 - val_loss: 16959.6074\n",
      "Epoch 26/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16950.9258 - val_loss: 16881.4121\n",
      "Epoch 27/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16872.4531 - val_loss: 16803.1504\n",
      "Epoch 28/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16793.9277 - val_loss: 16724.9004\n",
      "Epoch 29/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16715.4121 - val_loss: 16646.6035\n",
      "Epoch 30/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 16636.8906 - val_loss: 16568.3281\n",
      "Epoch 31/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16558.3633 - val_loss: 16490.0391\n",
      "Epoch 32/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16479.8184 - val_loss: 16411.7520\n",
      "Epoch 33/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16401.2910 - val_loss: 16333.4639\n",
      "Epoch 34/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16322.7676 - val_loss: 16255.2070\n",
      "Epoch 35/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16244.2520 - val_loss: 16176.9268\n",
      "Epoch 36/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 16165.7246 - val_loss: 16098.6562\n",
      "Epoch 37/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16087.1846 - val_loss: 16020.3945\n",
      "Epoch 38/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16008.6533 - val_loss: 15942.1113\n",
      "Epoch 39/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15930.1387 - val_loss: 15863.8291\n",
      "Epoch 40/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15851.6191 - val_loss: 15785.5479\n",
      "Epoch 41/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15773.0957 - val_loss: 15707.2842\n",
      "Epoch 42/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 15694.5576 - val_loss: 15629.0146\n",
      "Epoch 43/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15616.0264 - val_loss: 15550.7314\n",
      "Epoch 44/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15537.5078 - val_loss: 15472.4619\n",
      "Epoch 45/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15458.9678 - val_loss: 15394.1914\n",
      "Epoch 46/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15380.4434 - val_loss: 15315.9033\n",
      "Epoch 47/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15301.9268 - val_loss: 15237.6270\n",
      "Epoch 48/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 15223.3994 - val_loss: 15159.3672\n",
      "Epoch 49/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15144.8818 - val_loss: 15081.0908\n",
      "Epoch 50/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15066.3506 - val_loss: 15002.7939\n",
      "Epoch 51/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14987.8213 - val_loss: 14924.5234\n",
      "Epoch 52/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14909.2861 - val_loss: 14846.2334\n",
      "Epoch 53/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14830.7568 - val_loss: 14767.9502\n",
      "Epoch 54/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 14752.2402 - val_loss: 14689.6826\n",
      "Epoch 55/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14673.7158 - val_loss: 14611.3896\n",
      "Epoch 56/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14595.1885 - val_loss: 14533.1230\n",
      "Epoch 57/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14516.6709 - val_loss: 14454.8535\n",
      "Epoch 58/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14438.1152 - val_loss: 14376.5889\n",
      "Epoch 59/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 14359.6074 - val_loss: 14298.3047\n",
      "Epoch 60/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14281.0869 - val_loss: 14220.0381\n",
      "Epoch 61/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14202.5703 - val_loss: 14141.7490\n",
      "Epoch 62/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14124.0303 - val_loss: 14063.4590\n",
      "Epoch 63/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14045.4980 - val_loss: 13985.1885\n",
      "Epoch 64/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13966.9775 - val_loss: 13906.9062\n",
      "Epoch 65/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 13888.4482 - val_loss: 13828.6201\n",
      "Epoch 66/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13809.9326 - val_loss: 13750.3535\n",
      "Epoch 67/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13731.4043 - val_loss: 13672.0762\n",
      "Epoch 68/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13652.8682 - val_loss: 13593.7891\n",
      "Epoch 69/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13574.3428 - val_loss: 13515.5146\n",
      "Epoch 70/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13495.8076 - val_loss: 13437.2344\n",
      "Epoch 71/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 13417.2832 - val_loss: 13358.9766\n",
      "Epoch 72/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13338.7578 - val_loss: 13280.6982\n",
      "Epoch 73/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13260.2354 - val_loss: 13202.4209\n",
      "Epoch 74/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13181.7188 - val_loss: 13124.1553\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 1s 1ms/step - loss: 13103.1816 - val_loss: 13045.8916\n",
      "Epoch 76/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13024.6494 - val_loss: 12967.6055\n",
      "Epoch 77/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 12946.1230 - val_loss: 12889.3223\n",
      "Epoch 78/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12867.5996 - val_loss: 12811.0518\n",
      "Epoch 79/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12789.0771 - val_loss: 12732.7744\n",
      "Epoch 80/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12710.5527 - val_loss: 12654.4834\n",
      "Epoch 81/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12632.0078 - val_loss: 12576.2178\n",
      "Epoch 82/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12553.4932 - val_loss: 12497.9580\n",
      "Epoch 83/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 12474.9688 - val_loss: 12419.6680\n",
      "Epoch 84/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12396.4404 - val_loss: 12341.3936\n",
      "Epoch 85/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12317.9062 - val_loss: 12263.1172\n",
      "Epoch 86/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12239.3857 - val_loss: 12184.8594\n",
      "Epoch 87/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12160.8682 - val_loss: 12106.5898\n",
      "Epoch 88/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12082.3359 - val_loss: 12028.2822\n",
      "Epoch 89/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 12003.8047 - val_loss: 11950.0234\n",
      "Epoch 90/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11925.2744 - val_loss: 11871.7412\n",
      "Epoch 91/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11846.7549 - val_loss: 11793.4795\n",
      "Epoch 92/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11768.2217 - val_loss: 11715.1934\n",
      "Epoch 93/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11689.7090 - val_loss: 11636.9102\n",
      "Epoch 94/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11611.1914 - val_loss: 11558.6357\n",
      "Epoch 95/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 11532.6504 - val_loss: 11480.3398\n",
      "Epoch 96/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11454.1201 - val_loss: 11402.0723\n",
      "Epoch 97/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 11376.960 - 1s 1ms/step - loss: 11375.6055 - val_loss: 11323.8076\n",
      "Epoch 98/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11297.0566 - val_loss: 11245.5371\n",
      "Epoch 99/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11218.5273 - val_loss: 11167.2861\n",
      "Epoch 100/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11140.0146 - val_loss: 11088.9941\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = linear_model.fit(\n",
    "    train_x, train_y, \n",
    "    epochs=100,\n",
    "    # suppress logging\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos guardar o resultado de desempenho do modelo (loss) para depois comparar essa regressão multipla com a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results['linear_model'] = linear_model.evaluate(\n",
    "    test_x, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########REDE NEURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos agora aplicar uma rede neural (ou DNN - deep neural network)\n",
    "# Utilizaremos para tanto, vamos utilizar o método \"compile\" para treinar o modelo\n",
    "# Vamo utilizar a matriz de ativação relu, que é a mais comunmente usada, mas há outras\n",
    "# primeira camada (input): dimensão 13 (normalmente colocamos o número de variáveis utilizadas no modelo, dependente + independentes, que no nosso caso da 13) \n",
    "# segunda camada (intermediate layer): dimensão 8 \n",
    "# terceira camada (output): dimensão 1\n",
    "# a função abaixo constroi o modelo e compila o mesmo, como visto em model.compile\n",
    "# como estamos prevendo uma variável contínua e não binária, utilizamos o loss=\"mean_absolute_error\"\n",
    "# se estivéssemos prevendo uma variável dummy (binária, 0 ou 1), o loss seria \"binary_crossentropy\"\n",
    "# o optimizer poderia continuar sendo \"adam\" mas teríamos que acrescentaro termo metrics=['accuracy']\n",
    "# OBS: TENHO NO MEU GITHUB UM EXEMPLO DE REDE NEURAL PREVENDO VARIÁVEL DUMMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(13, activation='relu'),\n",
    "      layers.Dense(9, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizaremos todos os dados como insumo, melhoramos a\n",
    "# a performance ao utilizarmos o modelo na base de dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 12)                25        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                169       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 126       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 305\n",
      "Non-trainable params: 25\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# epochs=100 indica que o modelo será treinado passando 100 vezes pela base de treino\n",
    "# o argumento verbose=1 indica que queremos ver na tela as iterações do modelo\n",
    "# com verbose=0 o modelo é treinado e só mostra o tempo que gastou, pois especificamos %%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 18856.6934 - val_loss: 18514.5586\n",
      "Epoch 2/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17472.3203 - val_loss: 15861.8506\n",
      "Epoch 3/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13232.2412 - val_loss: 10160.7158\n",
      "Epoch 4/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 7333.3975 - val_loss: 5222.2329\n",
      "Epoch 5/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 3841.6375 - val_loss: 2955.8281\n",
      "Epoch 6/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 2648.8843 - val_loss: 2428.0737\n",
      "Epoch 7/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2208.4700 - val_loss: 2019.8021\n",
      "Epoch 8/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1822.9539 - val_loss: 1699.0311\n",
      "Epoch 9/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1610.4829 - val_loss: 1552.3021\n",
      "Epoch 10/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1448.0211 - val_loss: 1387.0222\n",
      "Epoch 11/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1269.6007 - val_loss: 1210.8622\n",
      "Epoch 12/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1108.3329 - val_loss: 1123.7118\n",
      "Epoch 13/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1086.4136 - val_loss: 1121.8468\n",
      "Epoch 14/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1085.0588 - val_loss: 1120.3123\n",
      "Epoch 15/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1083.8544 - val_loss: 1120.4725\n",
      "Epoch 16/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1083.0122 - val_loss: 1119.0972\n",
      "Epoch 17/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.8744 - val_loss: 1119.3026\n",
      "Epoch 18/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7660 - val_loss: 1119.4784\n",
      "Epoch 19/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8307 - val_loss: 1119.7522\n",
      "Epoch 20/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8492 - val_loss: 1119.7985\n",
      "Epoch 21/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6132 - val_loss: 1119.8038\n",
      "Epoch 22/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7185 - val_loss: 1119.1167\n",
      "Epoch 23/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7249 - val_loss: 1119.3699\n",
      "Epoch 24/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8914 - val_loss: 1119.0519\n",
      "Epoch 25/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7091 - val_loss: 1119.6082\n",
      "Epoch 26/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8038 - val_loss: 1119.3136\n",
      "Epoch 27/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7211 - val_loss: 1119.1843\n",
      "Epoch 28/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6847 - val_loss: 1119.4114\n",
      "Epoch 29/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6670 - val_loss: 1119.3258\n",
      "Epoch 30/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6489 - val_loss: 1120.5516\n",
      "Epoch 31/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7249 - val_loss: 1120.0187\n",
      "Epoch 32/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7377 - val_loss: 1118.8417\n",
      "Epoch 33/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6982 - val_loss: 1120.1951\n",
      "Epoch 34/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8868 - val_loss: 1118.8088\n",
      "Epoch 35/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6213 - val_loss: 1119.2018\n",
      "Epoch 36/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6639 - val_loss: 1119.3538\n",
      "Epoch 37/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6508 - val_loss: 1118.8740\n",
      "Epoch 38/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7249 - val_loss: 1119.4696\n",
      "Epoch 39/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7301 - val_loss: 1119.9819\n",
      "Epoch 40/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7140 - val_loss: 1119.5565\n",
      "Epoch 41/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7003 - val_loss: 1120.7920\n",
      "Epoch 42/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7948 - val_loss: 1119.6775\n",
      "Epoch 43/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.8608 - val_loss: 1119.0901\n",
      "Epoch 44/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7207 - val_loss: 1118.8945\n",
      "Epoch 45/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6848 - val_loss: 1119.2880\n",
      "Epoch 46/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8174 - val_loss: 1119.2550\n",
      "Epoch 47/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8000 - val_loss: 1119.2377\n",
      "Epoch 48/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.8406 - val_loss: 1120.3311\n",
      "Epoch 49/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7727 - val_loss: 1119.4469\n",
      "Epoch 50/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5792 - val_loss: 1118.4844\n",
      "Epoch 51/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6827 - val_loss: 1119.5807\n",
      "Epoch 52/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7213 - val_loss: 1119.7300\n",
      "Epoch 53/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.6678 - val_loss: 1118.9910\n",
      "Epoch 54/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6257 - val_loss: 1119.3370\n",
      "Epoch 55/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8221 - val_loss: 1120.9299\n",
      "Epoch 56/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7870 - val_loss: 1119.0927\n",
      "Epoch 57/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7322 - val_loss: 1120.3091\n",
      "Epoch 58/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.6194 - val_loss: 1119.8632\n",
      "Epoch 59/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.6476 - val_loss: 1118.9680\n",
      "Epoch 60/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7681 - val_loss: 1119.1676\n",
      "Epoch 61/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6428 - val_loss: 1118.8335\n",
      "Epoch 62/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7500 - val_loss: 1119.9357\n",
      "Epoch 63/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7795 - val_loss: 1119.4580\n",
      "Epoch 64/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6196 - val_loss: 1119.8722\n",
      "Epoch 65/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8140 - val_loss: 1119.8583\n",
      "Epoch 66/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8468 - val_loss: 1119.7142\n",
      "Epoch 67/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8164 - val_loss: 1119.9653\n",
      "Epoch 68/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8202 - val_loss: 1119.1781\n",
      "Epoch 69/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.8451 - val_loss: 1119.9221\n",
      "Epoch 70/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8032 - val_loss: 1119.6674\n",
      "Epoch 71/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6715 - val_loss: 1119.2461\n",
      "Epoch 72/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7733 - val_loss: 1118.8342\n",
      "Epoch 73/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7325 - val_loss: 1119.1694\n",
      "Epoch 74/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7817 - val_loss: 1119.9211\n",
      "Epoch 75/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6234 - val_loss: 1119.7220\n",
      "Epoch 76/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6891 - val_loss: 1119.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7374 - val_loss: 1120.6532\n",
      "Epoch 78/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7231 - val_loss: 1118.9478\n",
      "Epoch 79/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.6053 - val_loss: 1119.5483\n",
      "Epoch 80/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7784 - val_loss: 1118.9609\n",
      "Epoch 81/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7603 - val_loss: 1119.0853\n",
      "Epoch 82/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6942 - val_loss: 1119.2249\n",
      "Epoch 83/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6315 - val_loss: 1119.7052\n",
      "Epoch 84/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.6964 - val_loss: 1119.4767\n",
      "Epoch 85/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6923 - val_loss: 1119.4707\n",
      "Epoch 86/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6649 - val_loss: 1119.3320\n",
      "Epoch 87/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7091 - val_loss: 1119.0609\n",
      "Epoch 88/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7294 - val_loss: 1119.1788\n",
      "Epoch 89/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7000 - val_loss: 1119.2264\n",
      "Epoch 90/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7844 - val_loss: 1119.0284\n",
      "Epoch 91/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6650 - val_loss: 1120.2161\n",
      "Epoch 92/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7284 - val_loss: 1119.3853\n",
      "Epoch 93/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6923 - val_loss: 1119.5194\n",
      "Epoch 94/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7056 - val_loss: 1119.3878\n",
      "Epoch 95/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.8014 - val_loss: 1119.5206\n",
      "Epoch 96/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7279 - val_loss: 1118.8221\n",
      "Epoch 97/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7708 - val_loss: 1123.2555\n",
      "Epoch 98/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.8074 - val_loss: 1120.7600\n",
      "Epoch 99/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.7213 - val_loss: 1119.5260\n",
      "Epoch 100/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.7751 - val_loss: 1119.2614\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Novamente vamos salvar os resultados da previsão em nossa base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 902us/step - loss: 1036.6329\n"
     ]
    }
   ],
   "source": [
    "test_results['dnn_model'] = dnn_model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agora que já fiz todas as estimações, vamos comparar os resultados dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Valor_do_Aluguel]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>1036.632935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_model</th>\n",
       "      <td>11144.160156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean absolute error [Valor_do_Aluguel]\n",
       "dnn_model                                1036.632935\n",
       "linear_model                            11144.160156"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results, index=['Mean absolute error [Valor_do_Aluguel]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# É SEMPRE BOM LEMBRAR QUE MATRIZ DE CONFUSÃO E ACCURACY SCORE NÃO FAZEM SENTIDO PARA AVALIAR\n",
    "# UM MODELO DE REGRESSÃO, APENAS DE CLASSIFICAÇÃO. EM QUALQUER MODELO DE REGRESSÃO, POR MELHOR\n",
    "# QUE SEJA, A CHANCE DE ACERTAR EXATAMENTE O VALOR ATÉ NAS CASAS DECIMAIS É MÍNIMA\n",
    "# PARA REDES NEURAIS QUE PREVEEM A VARIÁVEIS CONTÍNUAS, A MELHOR FORMA DE COMPARAR MODELOS É\n",
    "# PELO ERRO ABSOLUTO MÉDIO, COMO FIZEMOS ACIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################SEGUNDA REDE NEURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos fazer uma nova rede neural apenas para padrão de comparação com as, vamos utilizar uma camada intermediária\n",
    "# a mais e aumentar a densidade das camadas para ver se há redução no erro\n",
    "# vamos acrescentar também uma camada Dropout, o que ele faz é aleatoriamente transformar alguns dos imputs para zero\n",
    "# ajudando a resuzar a ocorrência de overfitting. Tentei utilizar diferentes matrizes de ativação em camadas diferentes\n",
    "# mas não funcionou, vouti a colocar todas relu e melhorou o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ATENÇÃO: já tentei colocar mais camadas, assim como aumentar a densidade das mesmas, assim como mudar a matriz de ativação\n",
    "# para outra que não fosse a relu, porém não funcionou. Esse ai foi o que deu o melhor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## QUANDO EU FOR TENTAR REPLICAR O MÉTODO, DEVO FICAR COM ESTE TIPO DE MODELO\n",
    "## NA PRIMEIRA CAMADA COLOCAMOS O NÚMERO DE VARIÁVEIS UTILIZADAS NA BASE (INDEPENDENTES+DEPENDENTE)\n",
    "## A SEGUNDA CAMADA TEM A METADE DA PRIMEIRA (NO CASO, NÃO EXATAMENTE POIS A PRIMEIRA TEM DIMENSÃO ÍMPAR)\n",
    "## E A ÚLTIMA CAMADA, A DE RESULTADOS, APRESENTA APENAS UMA DIMENSÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_and_compile_model2(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(13, activation='relu'),\n",
    "      layers.Dense(6, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 12)                25        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 13)                169       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 285\n",
      "Trainable params: 260\n",
      "Non-trainable params: 25\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model2 = build_and_compile_model2(normalizer)\n",
    "dnn_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "784/784 [==============================] - 2s 1ms/step - loss: 18881.8535 - val_loss: 18646.9004\n",
      "Epoch 2/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18020.5000 - val_loss: 17013.2871\n",
      "Epoch 3/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 15388.9648 - val_loss: 13302.8955\n",
      "Epoch 4/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 10677.2432 - val_loss: 7963.8345\n",
      "Epoch 5/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 5443.4136 - val_loss: 3330.3660\n",
      "Epoch 6/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2341.7539 - val_loss: 1809.2697\n",
      "Epoch 7/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1507.2363 - val_loss: 1259.4230\n",
      "Epoch 8/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1111.5822 - val_loss: 1130.3961\n",
      "Epoch 9/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1092.1414 - val_loss: 1126.1141\n",
      "Epoch 10/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1088.7469 - val_loss: 1124.8137\n",
      "Epoch 11/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1086.7993 - val_loss: 1122.9830\n",
      "Epoch 12/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1085.2538 - val_loss: 1121.0295\n",
      "Epoch 13/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1083.8792 - val_loss: 1120.6909\n",
      "Epoch 14/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.8872 - val_loss: 1118.6589\n",
      "Epoch 15/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6094 - val_loss: 1119.0898\n",
      "Epoch 16/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4963 - val_loss: 1119.6129\n",
      "Epoch 17/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4325 - val_loss: 1119.3977\n",
      "Epoch 18/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.6564 - val_loss: 1118.7758\n",
      "Epoch 19/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3771 - val_loss: 1119.6381\n",
      "Epoch 20/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3926 - val_loss: 1119.2114\n",
      "Epoch 21/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3945 - val_loss: 1118.3622\n",
      "Epoch 22/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3691 - val_loss: 1119.2883\n",
      "Epoch 23/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4664 - val_loss: 1118.3864\n",
      "Epoch 24/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5149 - val_loss: 1118.8804\n",
      "Epoch 25/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3628 - val_loss: 1119.1095\n",
      "Epoch 26/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4026 - val_loss: 1119.0779\n",
      "Epoch 27/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4397 - val_loss: 1119.2761\n",
      "Epoch 28/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4758 - val_loss: 1119.0597\n",
      "Epoch 29/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4084 - val_loss: 1119.9102\n",
      "Epoch 30/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4330 - val_loss: 1118.9338\n",
      "Epoch 31/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4867 - val_loss: 1118.5468\n",
      "Epoch 32/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3512 - val_loss: 1119.0111\n",
      "Epoch 33/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4677 - val_loss: 1118.9642\n",
      "Epoch 34/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5483 - val_loss: 1119.4983\n",
      "Epoch 35/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3922 - val_loss: 1119.4520\n",
      "Epoch 36/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3540 - val_loss: 1118.8021\n",
      "Epoch 37/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3976 - val_loss: 1119.1680\n",
      "Epoch 38/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3463 - val_loss: 1118.5254\n",
      "Epoch 39/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4171 - val_loss: 1118.8258\n",
      "Epoch 40/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4706 - val_loss: 1119.3005\n",
      "Epoch 41/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4171 - val_loss: 1118.9299\n",
      "Epoch 42/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5181 - val_loss: 1118.8221\n",
      "Epoch 43/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3875 - val_loss: 1119.6110\n",
      "Epoch 44/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4604 - val_loss: 1119.2242\n",
      "Epoch 45/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3704 - val_loss: 1119.3340\n",
      "Epoch 46/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4340 - val_loss: 1120.0165\n",
      "Epoch 47/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3740 - val_loss: 1119.0187\n",
      "Epoch 48/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4055 - val_loss: 1119.4752\n",
      "Epoch 49/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3352 - val_loss: 1119.1896\n",
      "Epoch 50/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4095 - val_loss: 1118.7400\n",
      "Epoch 51/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4860 - val_loss: 1118.7452\n",
      "Epoch 52/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3828 - val_loss: 1119.8409\n",
      "Epoch 53/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5212 - val_loss: 1119.3800\n",
      "Epoch 54/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3795 - val_loss: 1119.3539\n",
      "Epoch 55/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4460 - val_loss: 1118.9054\n",
      "Epoch 56/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4468 - val_loss: 1119.8695\n",
      "Epoch 57/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5546 - val_loss: 1119.4292\n",
      "Epoch 58/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4805 - val_loss: 1118.8932\n",
      "Epoch 59/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3540 - val_loss: 1119.1781\n",
      "Epoch 60/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4440 - val_loss: 1119.6548\n",
      "Epoch 61/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4622 - val_loss: 1118.9623\n",
      "Epoch 62/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5039 - val_loss: 1119.3558\n",
      "Epoch 63/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3601 - val_loss: 1119.1428\n",
      "Epoch 64/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4536 - val_loss: 1119.4000\n",
      "Epoch 65/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4558 - val_loss: 1118.8712\n",
      "Epoch 66/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.2952 - val_loss: 1119.0830\n",
      "Epoch 67/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4493 - val_loss: 1119.4440\n",
      "Epoch 68/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4491 - val_loss: 1119.1958\n",
      "Epoch 69/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3870 - val_loss: 1119.5746\n",
      "Epoch 70/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3979 - val_loss: 1119.1790\n",
      "Epoch 71/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4303 - val_loss: 1119.3988\n",
      "Epoch 72/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.5027 - val_loss: 1119.6771\n",
      "Epoch 73/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4290 - val_loss: 1119.2612\n",
      "Epoch 74/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.2948 - val_loss: 1118.8553\n",
      "Epoch 75/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3522 - val_loss: 1119.1722\n",
      "Epoch 76/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4664 - val_loss: 1119.2860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3932 - val_loss: 1118.6469\n",
      "Epoch 78/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4039 - val_loss: 1119.7959\n",
      "Epoch 79/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4213 - val_loss: 1119.1654\n",
      "Epoch 80/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4277 - val_loss: 1118.8114\n",
      "Epoch 81/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4376 - val_loss: 1118.9177\n",
      "Epoch 82/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3732 - val_loss: 1119.0891\n",
      "Epoch 83/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4712 - val_loss: 1119.0887\n",
      "Epoch 84/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4742 - val_loss: 1119.3951\n",
      "Epoch 85/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4337 - val_loss: 1119.3413\n",
      "Epoch 86/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4435 - val_loss: 1118.8512\n",
      "Epoch 87/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4088 - val_loss: 1118.9109\n",
      "Epoch 88/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3529 - val_loss: 1118.8076\n",
      "Epoch 89/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.5363 - val_loss: 1119.1908\n",
      "Epoch 90/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3347 - val_loss: 1118.9868\n",
      "Epoch 91/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.3815 - val_loss: 1119.1044\n",
      "Epoch 92/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.5062 - val_loss: 1118.8143\n",
      "Epoch 93/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3495 - val_loss: 1118.7493\n",
      "Epoch 94/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4141 - val_loss: 1119.1221\n",
      "Epoch 95/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.4924 - val_loss: 1118.9910\n",
      "Epoch 96/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4910 - val_loss: 1118.7936\n",
      "Epoch 97/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1082.3849 - val_loss: 1119.1641\n",
      "Epoch 98/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4381 - val_loss: 1119.4042\n",
      "Epoch 99/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4572 - val_loss: 1119.2358\n",
      "Epoch 100/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1082.4042 - val_loss: 1118.7316\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = dnn_model2.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 1036.0969\n"
     ]
    }
   ],
   "source": [
    "test_results['dnn_model2'] = dnn_model2.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Valor_do_Aluguel]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>1036.632935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnn_model2</th>\n",
       "      <td>1036.096924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_model</th>\n",
       "      <td>11144.160156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean absolute error [Valor_do_Aluguel]\n",
       "dnn_model                                1036.632935\n",
       "dnn_model2                               1036.096924\n",
       "linear_model                            11144.160156"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results, index=['Mean absolute error [Valor_do_Aluguel]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# como o erro médio absoluto pouco variou, eu praticamente posso escolher qualquer uma das redes neurais, praticamente\n",
    "# o resultado é o mesmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################## SALVANDO O MELHOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "dnn_model.save('dnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E se você recarregar o modelo salvo, veja que este te dará o mesmo resultado\n",
    "# de previsão, provando que o modelo foi salvo corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [MPG]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>1036.632935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnn_model2</th>\n",
       "      <td>1036.096924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_model</th>\n",
       "      <td>11144.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reloaded</th>\n",
       "      <td>1036.632935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean absolute error [MPG]\n",
       "dnn_model                   1036.632935\n",
       "dnn_model2                  1036.096924\n",
       "linear_model               11144.160156\n",
       "reloaded                    1036.632935"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded = tf.keras.models.load_model('dnn_model')\n",
    "\n",
    "test_results['reloaded'] = reloaded.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esse último modelo que faremos abaixo foi o que ficou melhor, mas pouco variou em relção aos demais.\n",
    "# vamos ficar com o modelo que tem três camadas, é o que tem uma defesa teórica em relação às características\n",
    "# da base de dados utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_and_compile_model3(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(13, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 12)                25        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 13)                169       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 208\n",
      "Trainable params: 183\n",
      "Non-trainable params: 25\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model3 = build_and_compile_model3(normalizer)\n",
    "dnn_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18940.6797 - val_loss: 18887.2617\n",
      "Epoch 2/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 18892.3945 - val_loss: 18816.9121\n",
      "Epoch 3/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18803.6445 - val_loss: 18710.6445\n",
      "Epoch 4/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18682.2832 - val_loss: 18574.2715\n",
      "Epoch 5/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18532.7422 - val_loss: 18411.3105\n",
      "Epoch 6/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18357.7832 - val_loss: 18223.8652\n",
      "Epoch 7/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 18159.1875 - val_loss: 18013.2305\n",
      "Epoch 8/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 17937.6816 - val_loss: 17779.9004\n",
      "Epoch 9/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17693.6055 - val_loss: 17523.9902\n",
      "Epoch 10/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17427.3516 - val_loss: 17246.0938\n",
      "Epoch 11/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 17139.0293 - val_loss: 16946.0977\n",
      "Epoch 12/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16828.8555 - val_loss: 16624.2598\n",
      "Epoch 13/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16496.9668 - val_loss: 16280.7393\n",
      "Epoch 14/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 16143.7012 - val_loss: 15916.0332\n",
      "Epoch 15/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15769.0771 - val_loss: 15529.7158\n",
      "Epoch 16/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 15372.8535 - val_loss: 15121.7666\n",
      "Epoch 17/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14955.3203 - val_loss: 14692.5947\n",
      "Epoch 18/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 14516.4854 - val_loss: 14242.0381\n",
      "Epoch 19/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 14056.5342 - val_loss: 13770.7246\n",
      "Epoch 20/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13575.9648 - val_loss: 13278.4238\n",
      "Epoch 21/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 13074.0586 - val_loss: 12764.8447\n",
      "Epoch 22/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12551.2324 - val_loss: 12230.2451\n",
      "Epoch 23/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 12007.2363 - val_loss: 11674.5107\n",
      "Epoch 24/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 11443.6836 - val_loss: 11106.2236\n",
      "Epoch 25/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 10890.8994 - val_loss: 10576.3027\n",
      "Epoch 26/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 10362.1436 - val_loss: 10047.5439\n",
      "Epoch 27/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 9840.7061 - val_loss: 9536.6396\n",
      "Epoch 28/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 9323.2920 - val_loss: 9011.3252\n",
      "Epoch 29/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 8784.0449 - val_loss: 8468.0801\n",
      "Epoch 30/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 8239.0967 - val_loss: 7926.9258\n",
      "Epoch 31/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 7692.8350 - val_loss: 7384.7104\n",
      "Epoch 32/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 7136.6846 - val_loss: 6823.5522\n",
      "Epoch 33/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 6560.7935 - val_loss: 6243.4517\n",
      "Epoch 34/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 5966.9355 - val_loss: 5646.2739\n",
      "Epoch 35/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 5357.5034 - val_loss: 5039.1631\n",
      "Epoch 36/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 4772.4038 - val_loss: 4506.9399\n",
      "Epoch 37/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 4282.7012 - val_loss: 4094.4604\n",
      "Epoch 38/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 3928.3608 - val_loss: 3764.5759\n",
      "Epoch 39/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 3595.3848 - val_loss: 3457.2727\n",
      "Epoch 40/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 3316.3242 - val_loss: 3217.9053\n",
      "Epoch 41/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 3117.5276 - val_loss: 3050.4531\n",
      "Epoch 42/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 2949.2781 - val_loss: 2881.3364\n",
      "Epoch 43/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2777.0198 - val_loss: 2707.9614\n",
      "Epoch 44/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2600.2583 - val_loss: 2530.1624\n",
      "Epoch 45/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2431.1377 - val_loss: 2384.5647\n",
      "Epoch 46/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2304.6091 - val_loss: 2263.5879\n",
      "Epoch 47/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 2189.6660 - val_loss: 2150.7800\n",
      "Epoch 48/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2091.8562 - val_loss: 2073.4434\n",
      "Epoch 49/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 2019.2589 - val_loss: 2002.9902\n",
      "Epoch 50/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1947.2466 - val_loss: 1932.5945\n",
      "Epoch 51/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1875.2372 - val_loss: 1863.0581\n",
      "Epoch 52/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1804.1517 - val_loss: 1794.0929\n",
      "Epoch 53/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1732.7598 - val_loss: 1724.0105\n",
      "Epoch 54/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1660.2505 - val_loss: 1653.2880\n",
      "Epoch 55/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1611.9393 - val_loss: 1629.9464\n",
      "Epoch 56/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1588.0878 - val_loss: 1605.9424\n",
      "Epoch 57/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1563.4886 - val_loss: 1581.3323\n",
      "Epoch 58/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1538.3186 - val_loss: 1556.5868\n",
      "Epoch 59/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1513.5548 - val_loss: 1532.4037\n",
      "Epoch 60/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1489.0771 - val_loss: 1508.1467\n",
      "Epoch 61/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1464.4946 - val_loss: 1483.9167\n",
      "Epoch 62/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1439.6576 - val_loss: 1459.3228\n",
      "Epoch 63/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1414.6538 - val_loss: 1434.5421\n",
      "Epoch 64/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1389.2992 - val_loss: 1409.0942\n",
      "Epoch 65/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1363.6102 - val_loss: 1383.8457\n",
      "Epoch 66/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1337.6285 - val_loss: 1357.9276\n",
      "Epoch 67/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1311.4325 - val_loss: 1331.9042\n",
      "Epoch 68/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1284.8606 - val_loss: 1305.6431\n",
      "Epoch 69/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1257.8593 - val_loss: 1278.7133\n",
      "Epoch 70/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1230.5657 - val_loss: 1251.5984\n",
      "Epoch 71/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1202.8590 - val_loss: 1224.1273\n",
      "Epoch 72/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1174.6722 - val_loss: 1196.0112\n",
      "Epoch 73/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1146.1349 - val_loss: 1167.8042\n",
      "Epoch 74/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1117.3835 - val_loss: 1139.2975\n",
      "Epoch 75/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1089.1376 - val_loss: 1117.9102\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2843 - val_loss: 1117.8882\n",
      "Epoch 77/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2905 - val_loss: 1117.9506\n",
      "Epoch 78/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2870 - val_loss: 1117.9095\n",
      "Epoch 79/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2772 - val_loss: 1117.9927\n",
      "Epoch 80/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2742 - val_loss: 1117.9946\n",
      "Epoch 81/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1081.2855 - val_loss: 1117.9543\n",
      "Epoch 82/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2900 - val_loss: 1118.0461\n",
      "Epoch 83/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2877 - val_loss: 1118.0190\n",
      "Epoch 84/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2740 - val_loss: 1117.9518\n",
      "Epoch 85/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.3074 - val_loss: 1117.9706\n",
      "Epoch 86/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1081.2695 - val_loss: 1118.0305\n",
      "Epoch 87/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2848 - val_loss: 1118.0144\n",
      "Epoch 88/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2830 - val_loss: 1118.0048\n",
      "Epoch 89/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2876 - val_loss: 1117.9036\n",
      "Epoch 90/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2710 - val_loss: 1117.8842\n",
      "Epoch 91/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2802 - val_loss: 1117.9607\n",
      "Epoch 92/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1081.3029 - val_loss: 1118.0161\n",
      "Epoch 93/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2979 - val_loss: 1118.0122\n",
      "Epoch 94/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2968 - val_loss: 1117.9824\n",
      "Epoch 95/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2861 - val_loss: 1117.9175\n",
      "Epoch 96/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2778 - val_loss: 1118.0334\n",
      "Epoch 97/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2914 - val_loss: 1117.9155\n",
      "Epoch 98/100\n",
      "784/784 [==============================] - 1s 2ms/step - loss: 1081.2816 - val_loss: 1117.9111\n",
      "Epoch 99/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2719 - val_loss: 1117.9709\n",
      "Epoch 100/100\n",
      "784/784 [==============================] - 1s 1ms/step - loss: 1081.2972 - val_loss: 1117.9409\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = dnn_model3.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 967us/step - loss: 1035.3138\n"
     ]
    }
   ],
   "source": [
    "test_results['dnn_model3'] = dnn_model3.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Valor_do_Aluguel]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>1036.632935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnn_model2</th>\n",
       "      <td>1036.096924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnn_model3</th>\n",
       "      <td>1035.313843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_model</th>\n",
       "      <td>11144.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reloaded</th>\n",
       "      <td>1036.632935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean absolute error [Valor_do_Aluguel]\n",
       "dnn_model                                1036.632935\n",
       "dnn_model2                               1036.096924\n",
       "dnn_model3                               1035.313843\n",
       "linear_model                            11144.160156\n",
       "reloaded                                 1036.632935"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results, index=['Mean absolute error [Valor_do_Aluguel]']).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
